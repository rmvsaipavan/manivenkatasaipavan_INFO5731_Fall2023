{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmvsaipavan/manivenkatasaipavan_INFO5731_Fall2023/blob/main/Ramisetty_Exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "## The third In-class-exercise (due on 11:59 PM 10/08/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2htC-oV70ne"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IxYpko5sS1o"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "I want to categorize customer reviews of a mobile phone into different aspects such as \"Performance\", \"Camera Quality\", \"Battery Life\", \"Design\", and \"Overall Satisfaction\". Here are the features that we've used and why they might be helpful:\n",
        "Word Frequency Features, Sentiment Features, N-gram Features (bi-grams), Part-of-Speech (POS) Tag Features, N, amed Entity Features, Length-based Feature.\n",
        "\n",
        "\n",
        "1. Word Frequency Features:\n",
        "These features capture the frequency of specific words in the review.\n",
        "Helpful for identifying common keywords associated with different categories. For example, \"battery life\" might be a common phrase associated with the Battery Life category.\n",
        "\n",
        "2. Sentiment Features:\n",
        "These features quantify the sentiment of the review (positive, negative, neutral).\n",
        "Useful for identifying the overall sentiment towards different aspects of the mobile. For instance, a negative sentiment in the \"Camera Quality\" aspect might indicate dissatisfaction.\n",
        "\n",
        "3. N-gram Features (bi-grams):\n",
        "These features represent sequences of two words (bi-grams).\n",
        "Useful for capturing context and phrases that might be indicative of specific categories. For example, \"amazing camera\" might be indicative of a positive sentiment towards Camera Quality.\n",
        "\n",
        "4. Part-of-Speech (POS) Tag Features:\n",
        "These features label each word with its part of speech (e.g., noun, verb, adjective).\n",
        "Useful for identifying the linguistic structure of the review. For instance, identifying adjectives like \"amazing\" might indicate positive sentiment.\n",
        "\n",
        "5. Named Entity Features:\n",
        "These features identify entities like names of people, organizations, locations, etc.\n",
        "Useful for detecting mentions of specific entities that may be relevant to the categories. For example, if a review mentions a specific mobile brand or model, it might be relevant to the Design or Overall Satisfaction category.\n",
        "\n",
        "6. Length-based Features:\n",
        "These features include the length of the review, average word length, etc.\n",
        "Useful for capturing the complexity or verbosity of the review. For instance, a longer review might contain more detailed feedback about different aspects of the mobile.\n",
        "\n",
        "These features provide a diverse set of information about the text, allowing the machine learning model to capture various aspects of the reviews. This can help in making more accurate predictions about the categories. Keep in mind that the effectiveness of these features may vary depending on the specific dataset and task at hand. It's always a good practice to experiment with different feature sets and evaluate their performance.Length-based features are important as they provide a quantitative measure of the text data, which can be relevant in understanding the level of detail or verbosity in a review.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0-0CmDesS1p",
        "outputId": "e6e711c5-5e07-43c3-8fa5-d2fcd2398b0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Sai\n",
            "[nltk_data]     Pavan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to C:\\Users\\Sai\n",
            "[nltk_data]     Pavan\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Review: The battery life is amazing, but the camera quality could be better.\n",
            "Word Frequency: {'could': 1, 'is': 1, 'life': 1, ',': 1, '.': 1, 'amazing': 1, 'camera': 1, 'be': 1, 'quality': 1, 'but': 1, 'battery': 1, 'better': 1, 'the': 2}\n",
            "Sentiment Features: {'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.7391}\n",
            "Bi-grams: ['the battery', 'battery life', 'life is', 'is amazing', 'amazing ,', ', but', 'but the', 'the camera', 'camera quality', 'quality could', 'could be', 'be better', 'better .']\n",
            "POS Tags: ['DT', 'NN', 'NN', 'VBZ', 'JJ', ',', 'CC', 'DT', 'NN', 'NN', 'MD', 'VB', 'JJR', '.']\n",
            "Named Entities: []\n",
            "Length Features: {'num_words': 14, 'avg_word_length': 4.071428571428571}\n",
            "\n",
            "Review: The phone's design is sleek and elegant.\n",
            "Word Frequency: {'is': 1, 'elegant': 1, '.': 1, 'and': 1, 'phone': 1, 'sleek': 1, \"'s\": 1, 'the': 1, 'design': 1}\n",
            "Sentiment Features: {'neg': 0.0, 'neu': 0.659, 'pos': 0.341, 'compound': 0.4767}\n",
            "Bi-grams: ['the phone', \"phone 's\", \"'s design\", 'design is', 'is sleek', 'sleek and', 'and elegant', 'elegant .']\n",
            "POS Tags: ['DT', 'NN', 'POS', 'NN', 'VBZ', 'JJ', 'CC', 'JJ', '.']\n",
            "Named Entities: []\n",
            "Length Features: {'num_words': 9, 'avg_word_length': 3.7777777777777777}\n",
            "\n",
            "Review: I had a little trouble with the installation process, but the support team was quick to help. Great service!\n",
            "Word Frequency: {'with': 1, 'support': 1, 'help': 1, 'quick': 1, 'was': 1, 'a': 1, 'service': 1, 'but': 1, 'had': 1, ',': 1, '!': 1, '.': 1, 'to': 1, 'installation': 1, 'process': 1, 'team': 1, 'the': 2, 'great': 1, 'i': 1, 'trouble': 1, 'little': 1}\n",
            "Sentiment Features: {'neg': 0.061, 'neu': 0.469, 'pos': 0.47, 'compound': 0.9237}\n",
            "Bi-grams: ['i had', 'had a', 'a little', 'little trouble', 'trouble with', 'with the', 'the installation', 'installation process', 'process ,', ', but', 'but the', 'the support', 'support team', 'team was', 'was quick', 'quick to', 'to help', 'help .', '. great', 'great service', 'service !']\n",
            "POS Tags: ['PRP', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'CC', 'DT', 'NN', 'NN', 'VBD', 'JJ', 'TO', 'VB', '.', 'NNP', 'NN', '.']\n",
            "Named Entities: ['GPE']\n",
            "Length Features: {'num_words': 22, 'avg_word_length': 4.090909090909091}\n",
            "\n",
            "Review: I'm very satisfied with the overall performance of this mobile.Excellent processor makes me to take this mobile\n",
            "Word Frequency: {'satisfied': 1, 'with': 1, 'very': 1, 'of': 1, 'processor': 1, 'me': 1, 'this': 2, \"'m\": 1, 'to': 1, 'i': 1, 'mobile': 1, 'mobile.excellent': 1, 'makes': 1, 'take': 1, 'overall': 1, 'performance': 1, 'the': 1}\n",
            "Sentiment Features: {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'compound': 0.4754}\n",
            "Bi-grams: [\"i 'm\", \"'m very\", 'very satisfied', 'satisfied with', 'with the', 'the overall', 'overall performance', 'performance of', 'of this', 'this mobile.excellent', 'mobile.excellent processor', 'processor makes', 'makes me', 'me to', 'to take', 'take this', 'this mobile']\n",
            "POS Tags: ['PRP', 'VBP', 'RB', 'JJ', 'IN', 'DT', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NN', 'VBZ', 'PRP', 'TO', 'VB', 'DT', 'NN']\n",
            "Named Entities: []\n",
            "Length Features: {'num_words': 18, 'avg_word_length': 5.277777777777778}\n",
            "\n",
            "Review: Amazing camera performance but the night mode could be better\n",
            "Word Frequency: {'could': 1, 'amazing': 1, 'camera': 1, 'be': 1, 'mode': 1, 'performance': 1, 'but': 1, 'better': 1, 'the': 1, 'night': 1}\n",
            "Sentiment Features: {'neg': 0.0, 'neu': 0.561, 'pos': 0.439, 'compound': 0.7391}\n",
            "Bi-grams: ['amazing camera', 'camera performance', 'performance but', 'but the', 'the night', 'night mode', 'mode could', 'could be', 'be better']\n",
            "POS Tags: ['JJ', 'NN', 'NN', 'CC', 'DT', 'NN', 'NN', 'MD', 'VB', 'JJR']\n",
            "Named Entities: ['GPE']\n",
            "Length Features: {'num_words': 10, 'avg_word_length': 5.2}\n",
            "\n",
            "Review: Mobile phone is very good, go for it\n",
            "Word Frequency: {'it': 1, 'very': 1, 'is': 1, ',': 1, 'good': 1, 'mobile': 1, 'go': 1, 'for': 1, 'phone': 1}\n",
            "Sentiment Features: {'neg': 0.0, 'neu': 0.687, 'pos': 0.313, 'compound': 0.4927}\n",
            "Bi-grams: ['mobile phone', 'phone is', 'is very', 'very good', 'good ,', ', go', 'go for', 'for it']\n",
            "POS Tags: ['NNP', 'NN', 'VBZ', 'RB', 'JJ', ',', 'VB', 'IN', 'PRP']\n",
            "Named Entities: ['GPE']\n",
            "Length Features: {'num_words': 9, 'avg_word_length': 3.2222222222222223}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data]   Unzipping corpora\\words.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "\n",
        "# Sample customer reviews\n",
        "reviews = [\n",
        "    \"The battery life is amazing, but the camera quality could be better.\",\n",
        "    \"The phone's design is sleek and elegant.\",\n",
        "    \"I had a little trouble with the installation process, but the support team was quick to help. Great service!\",\n",
        "    \"I'm very satisfied with the overall performance of this mobile.\"\n",
        "    \"Excellent processor makes me to take this mobile\",\n",
        "    \"Amazing camera performance but the night mode could be better\",\n",
        "    \"Mobile phone is very good, go for it\"\n",
        "]\n",
        "\n",
        "# 1. Word Frequency Features\n",
        "def word_frequency(review):\n",
        "    tokens = word_tokenize(review.lower())\n",
        "    return {word: tokens.count(word) for word in set(tokens)}\n",
        "\n",
        "# 2. Sentiment Features\n",
        "def sentiment_features(review):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment = sia.polarity_scores(review)\n",
        "    return sentiment\n",
        "\n",
        "# 3. N-gram Features (bi-grams)\n",
        "def ngram_features(review, n=2):\n",
        "    tokens = word_tokenize(review.lower())\n",
        "    return [' '.join(gram) for gram in ngrams(tokens, n)]\n",
        "\n",
        "# 4. Part-of-Speech (POS) Tag Features\n",
        "def pos_tag_features(review):\n",
        "    tokens = word_tokenize(review)\n",
        "    return [tag for word, tag in pos_tag(tokens)]\n",
        "\n",
        "# 5. Named Entity Features\n",
        "def named_entity_features(review):\n",
        "    tokens = word_tokenize(review)\n",
        "    entities = ne_chunk(pos_tag(tokens))\n",
        "    return [chunk.label() for chunk in entities if hasattr(chunk, 'label')]\n",
        "\n",
        "# 6. Length-based Features\n",
        "def length_features(review):\n",
        "    tokens = word_tokenize(review)\n",
        "    return {\n",
        "        'num_words': len(tokens),\n",
        "        'avg_word_length': sum(len(word) for word in tokens) / len(tokens)\n",
        "    }\n",
        "\n",
        "# Extract features for each review\n",
        "for review in reviews:\n",
        "    print(\"\\nReview:\", review)\n",
        "    print(\"Word Frequency:\", word_frequency(review))\n",
        "    print(\"Sentiment Features:\", sentiment_features(review))\n",
        "    print(\"Bi-grams:\", ngram_features(review))\n",
        "    print(\"POS Tags:\", pos_tag_features(review))\n",
        "    print(\"Named Entities:\", named_entity_features(review))\n",
        "    print(\"Length Features:\", length_features(review))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z52mzw10sS1q",
        "outputId": "c16e3fe8-fab0-4554-ed25-8a5639ae3240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature: the, MI Score: 1.0114\n",
            "Feature: mobile, MI Score: 0.8676\n",
            "Feature: but, MI Score: 0.6931\n",
            "Feature: is, MI Score: 0.6931\n",
            "Feature: amazing, MI Score: 0.6365\n",
            "Feature: be, MI Score: 0.6365\n",
            "Feature: better, MI Score: 0.6365\n",
            "Feature: camera, MI Score: 0.6365\n",
            "Feature: could, MI Score: 0.6365\n",
            "Feature: performance, MI Score: 0.6365\n",
            "Feature: phone, MI Score: 0.6365\n",
            "Feature: very, MI Score: 0.6365\n",
            "Feature: with, MI Score: 0.6365\n",
            "Feature: and, MI Score: 0.4506\n",
            "Feature: battery, MI Score: 0.4506\n",
            "Feature: design, MI Score: 0.4506\n",
            "Feature: elegant, MI Score: 0.4506\n",
            "Feature: excellent, MI Score: 0.4506\n",
            "Feature: for, MI Score: 0.4506\n",
            "Feature: go, MI Score: 0.4506\n",
            "Feature: good, MI Score: 0.4506\n",
            "Feature: great, MI Score: 0.4506\n",
            "Feature: had, MI Score: 0.4506\n",
            "Feature: help, MI Score: 0.4506\n",
            "Feature: installation, MI Score: 0.4506\n",
            "Feature: it, MI Score: 0.4506\n",
            "Feature: life, MI Score: 0.4506\n",
            "Feature: little, MI Score: 0.4506\n",
            "Feature: makes, MI Score: 0.4506\n",
            "Feature: me, MI Score: 0.4506\n",
            "Feature: mode, MI Score: 0.4506\n",
            "Feature: night, MI Score: 0.4506\n",
            "Feature: of, MI Score: 0.4506\n",
            "Feature: overall, MI Score: 0.4506\n",
            "Feature: process, MI Score: 0.4506\n",
            "Feature: processor, MI Score: 0.4506\n",
            "Feature: quality, MI Score: 0.4506\n",
            "Feature: quick, MI Score: 0.4506\n",
            "Feature: satisfied, MI Score: 0.4506\n",
            "Feature: service, MI Score: 0.4506\n",
            "Feature: sleek, MI Score: 0.4506\n",
            "Feature: support, MI Score: 0.4506\n",
            "Feature: take, MI Score: 0.4506\n",
            "Feature: team, MI Score: 0.4506\n",
            "Feature: this, MI Score: 0.4506\n",
            "Feature: to, MI Score: 0.4506\n",
            "Feature: trouble, MI Score: 0.4506\n",
            "Feature: was, MI Score: 0.4506\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample labels for the reviews (for demonstration purposes)\n",
        "labels = [\"Battery Life\", \"Design\", \"Support\", \"Performance\", \"Camera Quality\", \"Overall Satisfaction\"]\n",
        "\n",
        "# Sample customer reviews\n",
        "reviews = [\n",
        "    \"The battery life is amazing, but the camera quality could be better.\",\n",
        "    \"The phone's design is sleek and elegant.\",\n",
        "    \"I had a little trouble with the installation process, but the support team was quick to help. Great service!\",\n",
        "    \"I'm very satisfied with the overall performance of this mobile. Excellent processor makes me take this mobile\",\n",
        "    \"Amazing camera performance but the night mode could be better\",\n",
        "    \"Mobile phone is very good, go for it\"\n",
        "]\n",
        "\n",
        "# 1. Create a Bag-of-Words representation of the reviews\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "\n",
        "# Check if the number of labels matches the number of samples\n",
        "if len(labels) != X.shape[0]:\n",
        "    raise ValueError(\"Number of labels must match the number of samples.\")\n",
        "\n",
        "# 2. Calculate Mutual Information scores\n",
        "mi_scores = mutual_info_classif(X, labels)\n",
        "\n",
        "# 3. Create a list of feature names (in this case, words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# 4. Combine feature names and their corresponding MI scores\n",
        "features_with_scores = list(zip(feature_names, mi_scores))\n",
        "\n",
        "# 5. Sort features by MI scores in descending order\n",
        "sorted_features = sorted(features_with_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the sorted features\n",
        "for feature, score in sorted_features:\n",
        "    print(f\"Feature: {feature}, MI Score: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "outputId": "9de0ddc0-8cb6-46d3-99f1-62cb75e48c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity: 0.8121\n",
            "Review: The battery life is amazing, but the camera quality could be better.\n",
            "\n",
            "Similarity: 0.7852\n",
            "Review: I'm very satisfied with the overall performance of this mobile.\n",
            "\n",
            "Similarity: 0.7418\n",
            "Review: The phone's design is sleek and elegant.\n",
            "\n",
            "Similarity: 0.7260\n",
            "Review: Mobile phone is very good, go for it\n",
            "\n",
            "Similarity: 0.7085\n",
            "Review: Amazing camera performance but the night mode could be better\n",
            "\n",
            "Similarity: 0.6797\n",
            "Review: I had a little trouble with the installation process, but the support team was quick to help. Great service!\n",
            "\n",
            "Similarity: 0.6675\n",
            "Review: Excellent processor makes me to take this mobile\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Sample customer reviews\n",
        "reviews = [\n",
        "    \"The battery life is amazing, but the camera quality could be better.\",\n",
        "    \"The phone's design is sleek and elegant.\",\n",
        "    \"I had a little trouble with the installation process, but the support team was quick to help. Great service!\",\n",
        "    \"I'm very satisfied with the overall performance of this mobile.\",\n",
        "    \"Excellent processor makes me to take this mobile\",\n",
        "    \"Amazing camera performance but the night mode could be better\",\n",
        "    \"Mobile phone is very good, go for it\"\n",
        "]\n",
        "\n",
        "# Define the query\n",
        "query = \"I'm looking for a mobile phone with a great camera quality and long battery life.\"\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and convert query to tensor\n",
        "query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "query_output = model(**query_tokens).last_hidden_state.mean(dim=1)\n",
        "\n",
        "# Tokenize and convert reviews to tensors\n",
        "review_tensors = [tokenizer(review, return_tensors='pt', padding=True, truncation=True) for review in reviews]\n",
        "review_outputs = [model(**tokens).last_hidden_state.mean(dim=1) for tokens in review_tensors]\n",
        "\n",
        "# Calculate cosine similarity between query and reviews\n",
        "similarities = [cosine_similarity(query_output.detach().numpy(), output.detach().numpy())[0][0] for output in review_outputs]\n",
        "\n",
        "# Combine similarities with reviews\n",
        "ranked_reviews = list(zip(reviews, similarities))\n",
        "\n",
        "# Sort reviews by similarity in descending order\n",
        "ranked_reviews.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print ranked reviews\n",
        "for review, similarity in ranked_reviews:\n",
        "    print(f\"Similarity: {similarity:.4f}\\nReview: {review}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X3vGKSVsS1r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nPNH_mCsS1r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}